# 性能优化

# 1、性能工具

## 1.1、HTTP 服务的性能测试

1. 压力测试工具

   * ab--ApacheBench

     ```shell
     ab -c200 -n1600 http://127.0.0.1:3000/download/
     ```

     ```shell
     Benchmarking 10.10.67.16 (be patient)
     Completed 100 requests
     Completed 200 requests
     Completed 300 requests
     Completed 400 requests
     Completed 500 requests
     Completed 600 requests
     Completed 700 requests
     Completed 800 requests
     Completed 900 requests
     Completed 1000 requests
     Finished 1000 requests
     
     # 服务器信息
     Server Software:
     Server Hostname:        10.10.67.16
     Server Port:            80
     
     Document Path:          /users  				# 请求路径
     Document Length:        676 bytes   		# 第一个成功返回的响应数据大小
     
     Concurrency Level:      10  						# 并发请求数量
     Time taken for tests:   1.260 seconds   # 总耗时
     Complete requests:      1000    				# 总请求数量
     Failed requests:        0   						# 请求失败数量
     Total transferred:      795000 bytes    # 从服务器接收数据大小
     HTML transferred:       676000 bytes    # 接收HTML大小
     Requests per second:    793.48 [/sec] (mean)   # ♨️ QPS 平均每秒请求数(总请求数量/总耗时) 793用户访问/s
     Time per request:       12.603 [ms] (mean) 		 # ♨️ 平均每批请求耗时（一批=总请求数量/并发请求数量）
     Time per request:       1.260 [ms] (mean, across all concurrent requests)   # ♨️ 平均每个请求耗时
     Transfer rate:          616.03 [Kbytes/sec] received 												# ♨️ 吞吐量 从服务器接收数据流量
     
     # 连接耗时详情
     Connection Times (ms)   
     #            最小值     均值     中值    最大值
                   min  mean[+/-sd] median   max
     Connect:        0    4  58.1      0    1063     # 与服务连接耗时
     Processing:     2    4   5.2      3      72     # 服务器处理请求耗时
     Waiting:        2    4   5.0      3      72     # 响应数据传输耗时
     Total:          2    8  58.2      4    1066     # 总耗时
     
     # 整体响应时间分布比
     Percentage of the requests served within a certain time (ms)    
       50%      4
       66%      4
       75%      5
       80%      5
       90%      7
       95%      9
       98%     20
       99%     41
      100%   1066 (longest request)
     ```

   * webbench

2. 找到性能瓶颈所在地

   * top----Linux 命令----监控 **cpu** & **内存**使用情况，进行上述压测时，同时服务器上跑 top ，就能看到 cpu 占用和 内存占用；
   * iostat----检测 i/o 设备**硬盘**的带宽；
   * 后端服务器----后端服务器 QPS 影响了 node 层的 QPS （少数）
     * 一般的瓶颈都是在 Node.js 的 cpu 运算能力上，体现在 cpu 占用率时 100% （js 代码写的不好）；

## 1.2、Node 性能分析工具

1. Node.js 自带 profile

   ```shell
   node --prof entry.js		# 生成 isolate-0x1046c2000-18349-v8.log 文件
   # 进行压测
   node --prof-process isolate-0x1046c2000-18349-v8.log > profile.txt	# 生成 txt 文件可以看到详细的文件执行耗时占比
   ```

2. Chrome devtool

   1. 输入命令行命令

   ```shell
   node --inspect-brk entry.js
   Debugger listening on ws://127.0.0.1:9229/5e01cf00-92ae-4f07-979c-de3ca48c9bfb
   For help, see: https://nodejs.org/en/docs/inspector
   Debugger attached.
   ```

   2. 浏览器打开 chrome://inspect
   3. 点击 Target (v14.16.0) 下的 inspect，出现 devtool
      * memory ---- 内存监控
      * profiler ---- 为 cpu监控
   4. 开启压测；
   5. 开启 cpu 监控录制⏺️按钮，进行压测，cpu 监控 stop ；
   6. 可以看到耗时占比；

# 2、代码优化

## 2.1、JS 代码性能优化

* Node.js HTTP 服务性能优化准则：
  * 提前计算（HTTP服务阶段的计算 --移动到--> 服务启动阶段）

```js
// 【优化1】readFileSync 从 app.use 中间件（http服务阶段）中提出来，到程序启动时做，极大减少了 readFileSync 的计算量占比；
// 				如果在mount里，也就是中间件里使用fs.readFileSync，相当于每一次请求都是从文件系统中取模板内容。
//				因为每一个http请求进来都会重新调用这堆中间件的；
//  			但你把fs.readFileSync提到外面，相当于提前把文件系统中的内容读取到内存中。中间件里是从内存中取得模板内容；
// 				从硬盘文件中取和从内存中取，高下立判，肯定是内存更快。

// 【优化2】把 readFileSync 的第二个参数 'utf-8' 删除，直接生成二进制 buffer 给到前端，减少了 '二进制' 与 'utf-8'之间的冗余转换（因为 node 底层 c++ 会用 ‘二进制’ 传给前端）；
const buffer = fs.readFileSync(__dirname + '/source/index.html');
app.use(
    mount('/', async (ctx) => {
        ctx.status = 200;
        ctx.type = 'html';
        ctx.body = buffer
    })
)
```

## 2.2、内存管理优化

* 使用 devtools 检测内存泄漏定位

  1. 命令行输入

     ```shell
     node --inspect-brk entry.js
     ```

  2. 浏览器打开 chrome://inspect

  3. 点击 Target (v14.16.0) 下的 inspect，出现 devtool

     * memory ---- 内存监控

  4. 开启压测，点击快照；

  5. 压测完毕，点击快照；

  6. 对比快照中，即可找到内存泄漏的变量；

* 节省内存最好的方式：

  * 使用 “池” （即，Node.js 中 buffer 的内存分配策略）

## 2.3、Node.js C++ 插件



# 3、多进程优化

## 3.1、为何需要子进程&子线程？

* 进程
  * 操作系统挂载运行程序的单元；
  * 拥有一些独立的资源，如内存等……
* 线程
  * 是比进程更小的单元；
  * 操作系统进行运算调度的单元；
  * 进程内的线程共享进程内的资源；
* Node.js 事件循环
  * 主线程运行 V8 与 javascript；
  * 多个子线程，通过事件循环被调度；
* 为了充分利用多核资源，Node.js 出现了子进程 & 子线程；

## 3.2、子进程&子线程的使用

1. ### 子进程----'child_process'

   * #### fork() & send()

   * fork方法直接创建一个子进程，执行Node脚本，`fork('./child.js')` fork会在父进程与子进程之间，建立一个通信管道，用于进程之间的通信；
   * 使用 child_process.fork() 生成新进程之后，就可以用 child.send(message, [sendHandle]) 向新进程发送消息。新进程中通过监听message事件，来获取消息；
   * 下面的例子是主进程的代码：

   ```js
   var child_process = require('child_process');
   var n = child_process.fork('./child.js');
   n.on('message', function(m) {
     console.log('PARENT got message:', m);
   });
   n.send({ hello: 'world' });
   ```

   上面代码中，fork方法返回一个代表进程间通信管道的对象，对该对象可以监听message事件，用来获取子进程返回的信息，也可以向子进程发送信息。

   child.js脚本的内容如下：

   ```js
   process.on('message', function(m) {
     console.log('CHILD got message:', m);
   });
   process.send({ foo: 'bar' });
   ```

   上面代码中，子进程监听message事件，并向父进程发送信息。

2. ### 子线程----''worker_threads''

   * 非必要，因为 Node.js 本身的子进程和事件循环机制已经够用了

3. ### 什么时候用多进程，什么时候用多线程？

   * 进程相比线程，传值和调用带来的性能消耗更高。但进程有独立的内存空间和计算资源，对整体运算性能的提升更高的。

## 3.3、cluster

1. ### cluster 模块简介

   * Node.js默认单进程运行，对于32位系统最高可以使用512MB内存，对于64位最高可以使用1GB内存。对于多核CPU的计算机来说，这样做效率很低，因为只有一个核在运行，其他核都在闲置。cluster模块就是为了解决这个问题而提出的；
   * cluster模块允许设立一个主进程和若干个worker进程，由主进程监控和协调worker进程的运行。worker之间采用进程间通信交换消息，cluster模块内置一个负载均衡器，采用Round-robin算法协调各个worker进程之间的负载。运行时，所有新建立的链接都由主进程完成，然后主进程再把TCP连接分配给指定的worker进程。

2. ### cluster 使用

   * 下面代码先判断当前进程是否为主进程（cluster.isMaster），如果是的，就按照CPU的核数，新建若干个worker进程；如果不是，说明当前进程是worker进程，则在该进程启动一个服务器程序。

     ```js
     var cluster = require('cluster');
     var os = require('os');
     
     if (cluster.isMaster){
       for (var i = 0, n = os.cpus().length / 2; i < n; i += 1){
         cluster.fork();
       }
     } else {
       http.createServer(function(req, res) {
         res.writeHead(200);
         res.end("hello world\n");
       }).listen(8000);
     }
     ```

   * 这段代码有2个缺点:

     1. 就是一旦work进程挂了，主进程无法知道。为解决这个问题，可以在主进程部署online事件和exit事件的监听函数。
     2. 占用了所有的 cpu ，会影响 Node.js 事件循环的处理效率，所以一般会占用一半；
        * 一方面不影响其它功能（事件循环）；
        * 另一方面，QPS 也不会比占用所有 cpu 时底很多；

   ```js
   var cluster = require('cluster');
   
   if(cluster.isMaster) {
     var numWorkers = require('os').cpus().length / 2;
     console.log('Master cluster setting up ' + numWorkers + ' workers...');
   
     for(var i = 0; i < numWorkers; i++) {
       cluster.fork();
     }
   
     cluster.on('online', function(worker) {
       console.log('Worker ' + worker.process.pid + ' is online');
     });
   
     cluster.on('exit', function(worker, code, signal) {
       console.log('Worker ' + worker.process.pid + ' died with code: ' + code + ', and signal: ' + signal);
       console.log('Starting a new worker');
       cluster.fork();
     });
   } else {
     http.createServer(function(req, res) {
       res.writeHead(200);
       res.end("hello world\n");
     }).listen(8000);
   }
   ```

3. ### cluster 源码解析

   * #### `cluster` 模块如何区分子进程和主进程？

     1. 判断环境变量里有没有 `NODE_UNIQUE_ID` 有则为子进程，无则为主进程

     ```js
     // cluster.js
     const childOrMaster = 'NODE_UNIQUE_ID' in process.env ? 'child' : 'master';
     module.exports = require(`internal/cluster/${childOrMaster}`);
     ```

     2. `NODE_UNIQUE_ID` 是从哪里来的？

        * 变量 `NODE_UNIQUE_ID` 是在主进程 `fork` 子进程时传递进去的参数，因此采用 `cluster.fork` 创建的子进程是一定包含 `NODE_UNIQUE_ID` 的，而直接使用 `child_process.fork` 的子进程是没有 `NODE_UNIQUE_ID` 的； 

          ```js
          // master.js
          const { fork } = require('child_process');
           
          cluster.workers = {}
           
          var ids = 0;
           
          cluster.fork = function(env) {	// 主进程 fork 子进程，
            const id = ++ ids;
            const workerProcess = createWorkerProcess(id, env);
            const worker = new Worker({
              id: id,
              process: workerProcess
            });
            cluster.workers[worker.id] = worker;
            return worker
          }
           
          function createWorkerProcess(id, env) {
            const workerEnv = { ...process.env, ...env, NODE_UNIQUE_ID: `${id}` };
            
            return fork(args, {		// 此时将 NODE_UNIQUE_ID 传入子进程
              env: workerEnv
            })
          }
          ```

   * #### 多个子进程共同侦听同一个端口为什么不会造成端口 `refuse error` ？

     1. 子进程会执行 `http.createServer` ；
     2. `http` 模块会调用 `net` 模块, 因为 `http.Server` 继承 `net.Server` ；
     3. 在 `net` 模块的 `listenInCluster` 中，将 `net` 创建服务器需要的数据，传递给子进程的 `cluster._getServer` 方法；
     4. 在子进程模块， `cluster._getServer` 方法将创建服务器需要的数据组装，并发送给主进程；
     5. 在主进程模块，将创建服务器的数据传递给 `RoundRobinHandle` ；
     6. 在 `round_robin_handle` 模块，创建服务器；
     7. 所以最终是主进程调用调度模块  `round_robin_handle` 创建的服务器，子进程监听同样端口不会报错；

     * 主进程`fork`子进程, 子进程中有显式创建服务器的操作，但实际上在`cluster`模式下, 子进程是把创建服务器所需要的数据发送给主进程, 主进程来隐式创建`TCP`服务器

   * #### round_robin_handle 的请求分发策略了解吗？

     * free 数组存储空闲子进程
     * handles 数组存储待处理请求

## 3.4、进程的守护与管理

* nodejs稳定性

  * 上线前检测不到 js 程序的问题，导致上线出现问题，需要进程守护；

* 简单的进程守护器：

  1. 监听 uncaughtException 事件，node.js 不会因为出现 uncaughtException 错误而退出进程；
  2. 偶尔进程会挂掉，5秒后，主进程重新分配一个子进程去补充挂掉的子进程；
  3. 内存使用过多（如，内存泄漏），进程自杀；
  4. 使用心跳包，每隔几秒，主进程向子进程发送 `ping` 并记录 `missed++` ，子进程收到后回复给主进程 `pong` 并记录 `missed--` ，若 `missed > 3` 超过，则说明子进程假死状态，则在主进程杀掉子进程；

  ```js
  /**
   * 简单的进程守护器
   */
  const cluster = require('cluster');
  
  if (cluster.isMaster) {
      for (let i = 0; i < require('os').cpus().length / 2; i++) {
          createWorker();
      }
  
      // ②--偶尔进程会挂掉，5秒后，主进程重新分配一个子进程去补充挂掉的子进程；
      cluster.on('exit', function () {
          setTimeout(() => {
              createWorker()
          }, 5000)
      })
  
    	// ④--createWorker 中添加心跳包
      function createWorker() {
          // 创建子进程并进行心跳监控
          var worker = cluster.fork();
  
          var missed = 0;// 没有回应的ping次数
  
          // 心跳
          var timer = setInterval(function () {
  
              // 三次没回应，杀之
              if (missed == 3) {
                  clearInterval(timer);
                  console.log(worker.process.pid + ' has become a zombie!');
                  process.kill(worker.process.pid);
                  return;
              }
              // 开始心跳
              missed++;
              worker.send('ping#' + worker.process.pid);
          }, 10000);
  
          worker.on('message', function (msg) {
              // 确认心跳回应。
              if (msg == 'pong#' + worker.process.pid) {
                  missed--;
              }
          });
  
          // 挂了就没必要再进行心跳了
          worker.on('exit', function () {
              clearInterval(timer);
          });
      }
  
  } else {
      // ①--监听 uncaughtException 事件，node.js 不会因为出现 uncaughtException 错误而退出进程；
      process.on('uncaughtException', function (err) {
          // 这里可以做写日志的操作
          console.log(err);
          // 监听该进程，会取消默认行为exit(1)，所以再需手动添加退出进程的默认行为
          process.exit(1);
      });
  
      // 回应心跳信息
      process.on('message', function (msg) {
          if (msg == 'ping#' + process.pid) {
              process.send('pong#' + process.pid);
          }
      });
  
      // ③--内存使用过多（如，内存泄漏），自杀
      if (process.memoryUsage().rss > 734003200) {
          console.log("oom")
          process.exit(1);
      }
  
      require('./app')
  }
  ```

# 4、架构优化

<img src="https://cdn.nlark.com/yuque/0/2021/jpeg/114317/1624011518436-f71f0a84-76b9-4226-8823-1277bb2fd67d.jpeg" alt="img" style="zoom:50%;" />

## 4.1、nginx 动静分离

* 静态内容：
  * 基本不变，不会因为请求参数的不同而改变；
  * 使用 nginx 代替 node 提供服务 qps 提升一倍，再使用 CDN 分发，并利用 HTTP 缓存进行静态内容的优化，性能可提升更多；
* 动态内容：
  * 因为请求参数不同而变动，变种数量不可枚举；
  * 使用大量的源站（相对 CDN 来说的内容来源）机进行承载，结合反向代理进行负载均衡，使用负载最小的源站对请求进行分发；

* 云服务器 nginx 静态实例提出来分离（实际上大部分情况下使用 CDN 进行静态文件网络分发）：

  1. 云服务器安装 nginx 并启动

     ```nginx
     yum install nginx					# 安装 nginx
     nginx											# 启动 nginx
     vi /etc/nginx/nginx.conf  # 打开 nginx 配置文件
     ```

  2. 将静态文件 html 下载页上传到云服务的 `/root/static/` ；

  3. 配置 nginx.conf 文件的 server.root 为 `/root/static/;` ；

     ```nginx
     server {
     		root		/root/static/;
     }
     ```

  4. 重启 nginx `nginx -s reload` ，静态文件下载页可以在线上显示；

  5. 在云服务器上启动 node.js 服务器，与 nginx 做对比，发现 nginx 的 qps 数是 node 的一倍；

## 4.2、反向代理与 redis

* 云服务器 nginx 动态实例：
  * 反向代理配置----路径匹配

  ```nginx
  server {
  	location ~ /node/(\d*) {# 正则表达式匹配下载页的课程id都是数字  # 此处为浏览器地址栏输入的内容
  		proxy_pass	http://127.0.0.1:3000/detail?columnid=$1;		# 访问浏览器输入地址后，此处转发到的真实请求node地址
      																												# nginx 优化减少了node koa 路由解析过程
  	}
  }
  
  # 重启 nginx 后，在浏览器输入服务器地址/要匹配的路径/columnid，如：http://129.182.79.157/node/12
  ```

  * 反向代理配置----负载均衡

  ```nginx
  upstream node.com {
    server 127.0.0.1:3000;
    server 127.0.0.1:3001;
  }
  server {
  	location ~ /node/(\d*) {
  		proxy_pass	http://node.com/detail?columnid=$1;		# 将要请求的真实node的服务器的地址改为 upstream 的别名
  	}
  }
  ```

  * 反向代理配置----缓存

  ```nginx
  server {
  	location ~ /node/(\d*) {
  		proxy_pass	http://node.com/detail?columnid=$1;
      proxy_cache		# 配置该路径内容的缓存到 nginx 层机器；
  	}
  }
  ```

* Node.js 层使用 Redis

  * 缓存

  * 请求失败兜底

    ```js
    app.use(async(ctx, ext) => {
      // 命中 redis ：缓存则返回缓存中的内容
      const res = await cacheRedis(ctx.url);
      if(res) {
        ctx.body = res;
        return;
      }
      await next();
      
      // 不命中 redis ：请求成功，将请求的内容缓存到 cacheRedis，并将备用内容写到 backupRedis
      if(ctx.status === 200) {
        cacheRedis.set(ctx.url, ctx.body, {expire: 979786868});
        backupRedis.set(ctx.url, ctx.body, {expire: 979786868});
      }
      
      // 请求失败，使用 backupRedis 兜底；
      if(ctx.status !== 200) {
        const res = await backupRedis(ctx.url);
        ctx.status = 200;
        ctx.body = res;
      }
    })
    ```

